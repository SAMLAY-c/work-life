---
created: 2025-12-08 20:35:04
published: 未知
source_url: https://mp.weixin.qq.com/s/7DsI7BX58kLKg3ENy8tf8A
source: WeWe RSS
rating: ⭐⭐⭐⭐
author: 量子位
author_description: 前沿科技资讯
tags: ["RSS文章", "微信公众号", "LLM", "Agent", "硬件", "行业分析", "编程", "AI视频", "LongCat-Video", "世界模型", "量子位"]
---

# 一手实测美团首个视频大模型，原生输出5分钟写实长视频

> [!abstract] AI 摘要
> **一句话总结**: 美团发布13.6B参数的LongCat-Video模型，擅长生成长视频。
>
> **核心亮点**:
> 1. 能生成长视频，如5分钟的不崩视频
> 2. 世界模型理解现实世界动态
>
> **商业潜力**: ⭐⭐⭐⭐

> [!info] 元数据
> - **作者/号主**: 量子位
> - **作者简介**: 前沿科技资讯
> - **发布时间**: 未知
> - **原文链接**: [https://mp.weixin.qq.com/s/7DsI7BX58kLKg3ENy8tf8A](https://mp.weixin.qq.com/s/7DsI7BX58kLKg3ENy8tf8A)
> - **AI标签**: RSS文章, 微信公众号, LLM, Agent, 硬件, 行业分析, 编程, AI视频, LongCat-Video, 世界模型, 量子位

> [!tip] AI 深度分析
> **主要观点**: LongCat-Video专注于模拟现实世界，尤其在物理规律和因果关系方面。对于美团来说，这能帮助预测交通拥堵和优化配送路径，提升业务效率。

---

## 📄 正文内容

周一美团发布了他们第一个AI视频模型，
LongCat-Video，
13.6B参数，单个模型就能完成文生视频，图生视频，视频续写，以及生成超长视频，输出的视频参数是720p，30fps 。但我自己电脑有点拖不动比较完整/长时间的测试，所以发动了面子果实，找到美团LongCat团队帮我开了内部测试权限。
所以在这篇文章你能看到LongCat-Video完全真实的效果，它到底能不能生成5分钟不崩的长视频，以及美团为什么要做AI视频？
先说结论，
美团LongCat-Video给我的感觉是，它玩的就是真实。
就比如这个视频，你能看出从第几秒开始是我用LongCat-Video续写出来的吗？
答案是2秒之后全部都是生成的内容，整个画面延续了原片自行车行驶的速度、环境，动态非常流畅真实。
LongCat-Video很擅长这种第一视角的穿越视频，甚至可以一次性生成5分钟的穿越视频，中间过程非常自然连贯，与真实世界非常相似。
技术团队给LongCat-Video的定位是
世界模型
，跟普通的视频模型追求生成风格多样、场景多样的视频的目标不同，世界模型，要
理解现实世界的动态、物理规律和因果关系。
英伟达在GTC上反复强调这个概念，他们给出的应用case，是给智能汽车模拟不同的交通流量模式、路况、天气和光照，是给机器人开发空间智能，是给交通枢纽给人群提供视频分析。
换而言之，世界模型的核心，不是电影制作机，它是模拟器，能投射出真实世界的状态。
所以我们这次测评，会专注于它对物理世界和因果逻辑的理解，尽可能的去看LongCat-Video对于真实世界的呈现程度。首先我做了一个经典滑板动作，和以往不同，我这次强调让它做出一个指定的Ollie动作，
对于这种非普遍的固定动作的完成，我没有补充说明，LongCat-Video靠“Ollie”这个提示词就跳起来然后稳稳落地，画面中各个元素的变化，包括人物和滑板之间的力作用里都很真实，可惜的是滑板本体转动的时候出现变形。
再看看LongCat-Video做出来的吃播视频，
是真的有在吃进去，食物进到了嘴巴里的同时盘子中的分量在减少，并且人物是有相应的表现力吃播表情的，如果清晰度和画面的打光可以少点锐化就好了。以后美团点外卖不会给每道菜都插入吃播吧。。。
再来就是人物讲解说话的镜头，
重点看人物的嘴形、眨眼、手部动作，虽然目前是没有声音的，但一分钟的画面里面没有出现过嘴形来回循环播放的片段，而且手部晃动这个香水的时候，瓶子里的液体也会对应细微晃动。
看完这几个case，我最大的感受是，LongCat-Video的世界观是朴素且正确的。
它可能画不出Sora那种宏大瑰丽、充满想象力的超现实史诗，但它能模拟出一个我们每天生活的、符合牛顿定律的世界。 而对于美团来说，后者远比前者重要一百倍。
最后我搞了点大白话说一下这次LongCat-Video的技术亮点，
为什么可以原生输出5分钟的不穿帮的视频，
它依托了一种叫视频续写任务的预训练方式。在训练的时候，LongCat-Video看的不是零碎的短片，而是大量的连续剧。它的大脑天生就在思考
接下来会发生什么
，而不是
这个画面应该长什么样
。
模型在看连续剧的时候，不是一帧一帧地看，而是一段一段、一个事件一个事件地看。它理解的是“动作的起承转合”，这是一种叫Block-Causal Attention的机制，这样生成的长时间的动作不会轻易断裂。
在生成长视频时，LongCat-Video还会把前面算过的不变的东西，比如背景里的那栋楼，先缓存起来，不用每一帧都重新算一遍，这样就可以提升到5分钟了
🔗
https://meituan-longcat.github.io/LongCat-Video/
这里面还有更多放出来的case，可以看到更多风格，现实交互和人物运动等等等等。
其实AI视频发展到现在，视频生成模型的分野已经出现了。
一类是为内容服务的，要的是视觉奇观，是多样化的画面风格，是创造一个又一个故事。
而另一类，就是世界模型，它们的目标是模拟现实，是做推演，为产业提供数据模拟。
他们并不是完全独立，切割开的，一个好的世界模型也会是好的视频模型。
对美团来说是早晚会踏出的一步，
他们的核心业务，本质上就是一场规模庞大，每秒都在发生的物理实验。
不需要AI去生成一个赛博朋克城市，
但需要AI告诉他们，
几点钟，哪个路口会开始堵车？ 一个骑手在暴雨天气下，穿过一个有积水的十字路口，需要额外多花多少秒？ 一个无人机配送包裹，在十五公里的时速下，侧面吹来的三级风，会如何影响它的电量消耗和稳定性？
这些，全部都是世界模型可以解决的问题。
我期待它能接入更多来自美团自有业务的真实世界数据，
模拟一场从国贸到望京的晚高峰拥堵，模拟一个外卖订单在雷暴天气下的最优配送路径，模拟一栋写字楼在午餐高峰期的电梯运行和人流动态？
当一个AI视频模型开始真正理解并模拟我们脚下的这片土地时，
它就不再是少数人的工具。
这是美团做AI视频，
让我感到兴奋的点。
@ 作者 / 卡尔 & 阿汤
最后，感谢你看到这里👏
如果喜欢这篇文章，不妨顺手给我们
点赞👍｜在看👀｜转发📪｜评论📣
如果想要第一时间收到推送，不妨给我个星标
🌟
更多的内容正在不断填坑中……

---
> 💡 *此文章通过 WeWe RSS 自动抓取，AI分析由 SiliconFlow 提供*
