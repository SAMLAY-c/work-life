# AIäº§å“åŒ–ä¸å·¥ç¨‹å®ç°å±‚

> **å®šä½**ï¼šå°†å‰æ²¿AIæŠ€æœ¯è½¬åŒ–ä¸ºå¯ç¨³å®šè¿è¡Œçš„é”¦ä¹¦æ•™è‚²äº§å“åŠŸèƒ½ï¼Œå®ç°æŠ€æœ¯è½åœ°çš„æœ€åä¸€å…¬é‡Œ

## ğŸ¯ å·¥ç¨‹åŒ–æ ¸å¿ƒåŸåˆ™

**"ç¨³å®šæ€§ã€å¯æ‰©å±•æ€§ã€æˆæœ¬å¯æ§æ€§"**æ˜¯AIå·¥ç¨‹åŒ–çš„ä¸‰ä¸ªæ ¸å¿ƒè¦ç´ ã€‚æ¯ä¸ªAIåŠŸèƒ½éƒ½å¿…é¡»ç»è¿‡ä¸¥æ ¼çš„å·¥ç¨‹åŒ–æ”¹é€ æ‰èƒ½æŠ•å…¥ç”Ÿäº§ä½¿ç”¨ã€‚

## ğŸ—ï¸ æŠ€æœ¯æ¶æ„åˆ†å±‚

### åŸºç¡€è®¾æ–½å±‚
- **ç®—åŠ›ç®¡ç†**ï¼šGPUèµ„æºè°ƒåº¦ã€æ¨¡å‹æœåŠ¡éƒ¨ç½²
- **æ•°æ®ç®¡é“**ï¼šå®æ—¶æ•°æ®å¤„ç†ã€æ¨¡å‹è®­ç»ƒæ•°æ®æµ
- **ç›‘æ§ç³»ç»Ÿ**ï¼šæ€§èƒ½ç›‘æ§ã€é”™è¯¯è¿½è¸ªã€æˆæœ¬æ§åˆ¶

### ç®—æ³•æœåŠ¡å±‚
- **æ¨¡å‹æœåŠ¡**ï¼šæ ‡å‡†åŒ–APIæ¥å£ã€æ¨¡å‹ç‰ˆæœ¬ç®¡ç†
- **æ¨ç†ä¼˜åŒ–**ï¼šæ¨¡å‹å‹ç¼©ã€æ¨ç†åŠ é€Ÿã€ç¼“å­˜ç­–ç•¥
- **å®‰å…¨æ§åˆ¶**ï¼šè¾“å…¥è¿‡æ»¤ã€è¾“å‡ºå®¡æŸ¥ã€æƒé™ç®¡ç†

### ä¸šåŠ¡åº”ç”¨å±‚
- **åŠŸèƒ½é›†æˆ**ï¼šä¸é”¦ä¹¦ç°æœ‰ç³»ç»Ÿçš„æ— ç¼é›†æˆ
- **ç”¨æˆ·ä½“éªŒ**ï¼šå“åº”é€Ÿåº¦ã€äº¤äº’æµç•…åº¦ã€é”™è¯¯å¤„ç†
- **æ•°æ®é—­ç¯**ï¼šæ•ˆæœè¿½è¸ªã€A/Bæµ‹è¯•ã€æŒç»­ä¼˜åŒ–

---

## ğŸ“ ç›®å½•ç»“æ„

### [01-å‰ç«¯AIé›†æˆ](./01-å‰ç«¯AIé›†æˆ/)
Vercel AI SDKã€Next.js App Routerç­‰å‰ç«¯AIæŠ€æœ¯é›†æˆæ–¹æ¡ˆ

### [02-åç«¯AIæœåŠ¡](./02-åç«¯AIæœåŠ¡/)
FastAPIã€Celeryå¼‚æ­¥ä»»åŠ¡ã€Serverless GPUæ¨ç†ç­‰åç«¯æ¶æ„

### [03-å‘é‡æ•°æ®åº“å®æˆ˜](./03-å‘é‡æ•°æ®åº“å®æˆ˜/)
Pineconeã€Qdrantã€Milvusç­‰å‘é‡æ•°æ®åº“çš„é€‰å‹å’Œä¼˜åŒ–

---

## ğŸ”§ å·¥ç¨‹åŒ–æ ‡å‡†

### ä»£ç è´¨é‡æ ‡å‡†
```python
# AIåŠŸèƒ½ä»£ç ç¤ºä¾‹
class AIBasedQuestionGenerator:
    """
    åŸºäºAIçš„é¢˜ç›®ç”Ÿæˆå™¨

    å·¥ç¨‹åŒ–è¦æ±‚ï¼š
    1. å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œé™çº§æœºåˆ¶
    2. æ€§èƒ½ç›‘æ§å’Œæ—¥å¿—è®°å½•
    3. æˆæœ¬æ§åˆ¶å’Œç”¨é‡ç»Ÿè®¡
    4. å®‰å…¨æ€§æ£€æŸ¥å’Œå†…å®¹è¿‡æ»¤
    """

    def __init__(self):
        self.model_client = self._initialize_model_client()
        self.cache = RedisCache()
        self.monitor = PerformanceMonitor()
        self.cost_tracker = CostTracker()
        self.content_filter = ContentSafetyFilter()

    async def generate_question(self, concept: str, difficulty: float) -> Dict:
        """ç”Ÿæˆé¢˜ç›®ï¼ˆå·¥ç¨‹åŒ–ç‰ˆæœ¬ï¼‰"""
        try:
            # 1. å‚æ•°éªŒè¯
            self._validate_input_parameters(concept, difficulty)

            # 2. ç¼“å­˜æ£€æŸ¥
            cache_key = f"question:{concept}:{difficulty:.2f}"
            cached_result = await self.cache.get(cache_key)
            if cached_result:
                return cached_result

            # 3. æ€§èƒ½ç›‘æ§å¼€å§‹
            start_time = time.time()

            # 4. æ¨¡å‹è°ƒç”¨
            result = await self._call_ai_model(concept, difficulty)

            # 5. å®‰å…¨æ£€æŸ¥
            if not self.content_filter.is_safe(result):
                raise ContentSafetyError("Generated content failed safety check")

            # 6. è´¨é‡éªŒè¯
            quality_score = self._assess_quality(result)
            if quality_score < 0.7:
                raise QualityError("Generated content quality too low")

            # 7. ç¼“å­˜ç»“æœ
            await self.cache.set(cache_key, result, ttl=3600)

            # 8. æ€§èƒ½ç›‘æ§ç»“æŸ
            execution_time = time.time() - start_time
            self.monitor.record_execution_time("question_generation", execution_time)

            # 9. æˆæœ¬è¿½è¸ª
            self.cost_tracker.record_usage("question_generation", result['token_usage'])

            return result

        except Exception as e:
            # é”™è¯¯å¤„ç†å’Œé™çº§æœºåˆ¶
            fallback_result = await self._generate_fallback_question(concept, difficulty)
            self.monitor.record_error("question_generation", str(e))
            return fallback_result
```

### éƒ¨ç½²å’Œè¿ç»´æ ‡å‡†
```yaml
# Dockerå®¹å™¨åŒ–éƒ¨ç½²ç¤ºä¾‹
ai-service-deployment:
  é•œåƒæ„å»º:
    base_image: python:3.9-slim
    requirements: requirements.txt
    model_files: /app/models/

  èµ„æºé…ç½®:
    cpu: "2"
    memory: "8Gi"
    gpu: "1"  # å¦‚æœéœ€è¦GPUæ¨ç†

  å¥åº·æ£€æŸ¥:
    path: "/health"
    interval: "30s"
    timeout: "10s"
    retries: 3

  ç¯å¢ƒå˜é‡:
    MODEL_API_KEY: ${MODEL_API_KEY}
    REDIS_URL: ${REDIS_URL}
    MONITORING_ENABLED: "true"

  æ°´å¹³æ‰©å±•:
    min_replicas: 2
    max_replicas: 10
    cpu_threshold: 70%
    memory_threshold: 80%
```

---

## ğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯•

### å…³é”®æ€§èƒ½æŒ‡æ ‡
| åŠŸèƒ½æ¨¡å— | å“åº”æ—¶é—´(P95) | å¯ç”¨æ€§ | é”™è¯¯ç‡ | æˆæœ¬/è°ƒç”¨ |
|---------|---------------|--------|--------|-----------|
| é¢˜ç›®ç”Ÿæˆ | <3ç§’ | >99.5% | <1% | Â¥0.15 |
| æ™ºèƒ½ç­”ç–‘ | <5ç§’ | >99.0% | <2% | Â¥0.25 |
| å­¦ä¹ è·¯å¾„è§„åˆ’ | <2ç§’ | >99.8% | <0.5% | Â¥0.08 |
| å†…å®¹å®¡æ ¸ | <1ç§’ | >99.9% | <0.1% | Â¥0.02 |

### æ€§èƒ½ä¼˜åŒ–ç­–ç•¥
```python
class PerformanceOptimizer:
    """AIæœåŠ¡æ€§èƒ½ä¼˜åŒ–å™¨"""

    def __init__(self):
        self.connection_pool = ConnectionPool(max_size=100)
        self.request_batcher = RequestBatcher(batch_size=10, timeout=0.5)
        self.response_cache = ResponseCache(ttl=300)
        self.model_warmup = ModelWarmup()

    async def optimize_inference(self, requests: List[Request]) -> List[Response]:
        """ä¼˜åŒ–æ¨ç†æ€§èƒ½"""
        # 1. æ‰¹é‡å¤„ç†
        batched_requests = self.request_batcher.batch(requests)

        # 2. ç¼“å­˜æŸ¥è¯¢
        cached_responses = await self.response_cache.get_batch(requests)
        uncached_requests = [r for r in requests if r.id not in cached_responses]

        # 3. æ¨¡å‹æ¨ç†
        if uncached_requests:
            model_responses = await self._batch_inference(uncached_requests)
            await self.response_cache.set_batch(model_responses)
        else:
            model_responses = []

        # 4. ç»“æœåˆå¹¶
        all_responses = {**cached_responses, **{r.id: r for r in model_responses}}
        return [all_responses[r.id] for r in requests]
```

---

## ğŸ’° æˆæœ¬æ§åˆ¶æœºåˆ¶

### æˆæœ¬ç›‘æ§å’Œé¢„è­¦
```python
class CostController:
    """AIæœåŠ¡æˆæœ¬æ§åˆ¶å™¨"""

    def __init__(self):
        self.daily_budget = 10000  # æ—¥é¢„ç®—Â¥10,000
        self.user_rate_limit = 100  # ç”¨æˆ·å•æ—¥é™é¢100æ¬¡è°ƒç”¨
        self.cost_tracker = CostTracker()

    async def check_budget(self, user_id: str, estimated_cost: float) -> bool:
        """æ£€æŸ¥é¢„ç®—æ˜¯å¦å……è¶³"""
        # 1. æ£€æŸ¥å…¨å±€æ—¥é¢„ç®—
        daily_spent = await self.cost_tracker.get_daily_spending()
        if daily_spent + estimated_cost > self.daily_budget:
            raise BudgetExceededError("Daily budget exceeded")

        # 2. æ£€æŸ¥ç”¨æˆ·é™é¢
        user_usage = await self.cost_tracker.get_user_usage(user_id)
        if user_usage['call_count'] >= self.user_rate_limit:
            raise RateLimitExceededError("User rate limit exceeded")

        return True

    def get_cost_optimization_suggestions(self) -> List[str]:
        """è·å–æˆæœ¬ä¼˜åŒ–å»ºè®®"""
        suggestions = []

        usage_stats = self.cost_tracker.get_usage_statistics()

        if usage_stats['peak_hour_ratio'] > 0.4:
            suggestions.append("è€ƒè™‘åœ¨é«˜å³°æ—¶æ®µä½¿ç”¨æ›´ä¾¿å®œçš„æ¨¡å‹")

        if usage_stats['cache_hit_rate'] < 0.3:
            suggestions.append("å¢åŠ ç¼“å­˜æ—¶é—´ä»¥æé«˜å‘½ä¸­ç‡")

        if usage_stats['avg_tokens_per_request'] > 1000:
            suggestions.append("ä¼˜åŒ–promptä»¥å‡å°‘tokenä½¿ç”¨")

        return suggestions
```

---

## ğŸ”’ å®‰å…¨ä¸åˆè§„

### æ•°æ®å®‰å…¨æªæ–½
```yaml
æ•°æ®å®‰å…¨:
  åŠ å¯†ä¼ è¾“: TLS 1.3
  æ•°æ®å­˜å‚¨: AES-256åŠ å¯†
  è®¿é—®æ§åˆ¶: RBACæƒé™ç®¡ç†
  å®¡è®¡æ—¥å¿—: å®Œæ•´çš„æ“ä½œè®°å½•

éšç§ä¿æŠ¤:
  æ•°æ®è„±æ•: æ•æ„Ÿä¿¡æ¯è‡ªåŠ¨è„±æ•
  æœ€å°åŒ–åŸåˆ™: åªæ”¶é›†å¿…è¦æ•°æ®
  ç”¨æˆ·æ§åˆ¶: æ•°æ®åˆ é™¤å’Œå¯¼å‡ºæƒé™
  åˆè§„æ£€æŸ¥: å®šæœŸéšç§åˆè§„å®¡è®¡

å†…å®¹å®‰å…¨:
  è¾“å…¥è¿‡æ»¤: æ¶æ„å†…å®¹æ£€æµ‹
  è¾“å‡ºå®¡æ ¸: AIç”Ÿæˆå†…å®¹å®‰å…¨æ£€æŸ¥
  å®æ—¶ç›‘æ§: ä¸å®‰å…¨å†…å®¹å®æ—¶å‘ç°
  å¿«é€Ÿå“åº”: å®‰å…¨äº‹ä»¶åº”æ€¥å¤„ç†
```

### APIå®‰å…¨å®ç°
```python
class SecureAIAPI:
    """å®‰å…¨çš„AIæœåŠ¡API"""

    def __init__(self):
        self.rate_limiter = RateLimiter()
        self.authenticator = Authenticator()
        self.input_sanitizer = InputSanitizer()
        self.output_filter = OutputFilter()
        self.audit_logger = AuditLogger()

    async def secure_generate(self, request: AIRequest) -> AIResponse:
        """å®‰å…¨çš„å†…å®¹ç”Ÿæˆæ¥å£"""
        # 1. èº«ä»½è®¤è¯
        user = await self.authenticator.authenticate(request.token)

        # 2. æƒé™æ£€æŸ¥
        if not self._check_permissions(user, request.operation):
            raise PermissionDeniedError()

        # 3. é™æµæ£€æŸ¥
        if not await self.rate_limiter.check_limit(user.id):
            raise RateLimitExceededError()

        # 4. è¾“å…¥å®‰å…¨æ£€æŸ¥
        sanitized_input = self.input_sanitizer.sanitize(request.input)

        # 5. è®°å½•å®¡è®¡æ—¥å¿—
        self.audit_logger.log_request(user.id, request)

        # 6. æ‰§è¡ŒAIç”Ÿæˆ
        try:
            result = await self._generate_content(sanitized_input)

            # 7. è¾“å‡ºå®‰å…¨æ£€æŸ¥
            filtered_result = self.output_filter.filter(result)

            # 8. è®°å½•æˆåŠŸæ—¥å¿—
            self.audit_logger.log_success(user.id, request, filtered_result)

            return filtered_result

        except Exception as e:
            # 9. è®°å½•é”™è¯¯æ—¥å¿—
            self.audit_logger.log_error(user.id, request, str(e))
            raise
```

---

## ğŸ“ˆ ç›‘æ§å’Œè¿ç»´

### å¤šç»´åº¦ç›‘æ§ä½“ç³»
```python
class AIMonitoringSystem:
    """AIæœåŠ¡ç›‘æ§ç³»ç»Ÿ"""

    def __init__(self):
        self.metrics_collector = MetricsCollector()
        self.alert_manager = AlertManager()
        self.dashboard = MonitoringDashboard()

    def setup_monitoring(self):
        """è®¾ç½®ç›‘æ§æŒ‡æ ‡"""

        # æ€§èƒ½æŒ‡æ ‡
        self.metrics_collector.track_metric(
            "ai_response_time",
            tags=["model", "endpoint"]
        )

        # ä¸šåŠ¡æŒ‡æ ‡
        self.metrics_collector.track_metric(
            "question_generation_quality",
            tags=["subject", "difficulty"]
        )

        # æˆæœ¬æŒ‡æ ‡
        self.metrics_collector.track_metric(
            "api_cost_per_call",
            tags=["model", "operation"]
        )

        # ç”¨æˆ·ä½“éªŒæŒ‡æ ‡
        self.metrics_collector.track_metric(
            "user_satisfaction_score",
            tags=["feature", "user_segment"]
        )

        # é”™è¯¯æŒ‡æ ‡
        self.metrics_collector.track_metric(
            "error_rate",
            tags=["error_type", "endpoint"]
        )

    def setup_alerts(self):
        """è®¾ç½®å‘Šè­¦è§„åˆ™"""

        # æ€§èƒ½å‘Šè­¦
        self.alert_manager.create_alert(
            name="high_response_time",
            condition="ai_response_time_p95 > 5s",
            severity="warning"
        )

        # æˆæœ¬å‘Šè­¦
        self.alert_manager.create_alert(
            name="daily_budget_exceeded",
            condition="daily_cost > daily_budget * 0.8",
            severity="critical"
        )

        # è´¨é‡å‘Šè­¦
        self.alert_manager.create_alert(
            name="low_content_quality",
            condition="content_quality_avg < 0.7",
            severity="warning"
        )
```

---

## ğŸ”„ CI/CDå’Œè‡ªåŠ¨åŒ–

### AIæ¨¡å‹çš„CI/CDæµç¨‹
```yaml
# AIæ¨¡å‹éƒ¨ç½²æµæ°´çº¿
ai-model-pipeline:
  stages:
    - name: model_validation
      steps:
        - validate_model_performance
        - check_model_drift
        - safety_content_test

    - name: integration_testing
      steps:
        - api_integration_test
        - load_testing
        - end_to_end_test

    - name: canary_deployment
      steps:
        - deploy_to_canary
        - monitor_canary_metrics
        - gradual_traffic_shift

    - name: production_deployment
      steps:
        - deploy_to_production
        - health_check_validation
        - performance_baseline_check

  rollback_strategy:
    automatic: true
    trigger_conditions:
      - error_rate > 5%
      - response_time_p95 > 10s
      - user_satisfaction < 4.0
```

---

## ğŸ“š å¼€å‘æœ€ä½³å®è·µ

### ä»£ç ç»„ç»‡è§„èŒƒ
```
ai-services/
â”œâ”€â”€ core/                    # æ ¸å¿ƒAIç®—æ³•
â”‚   â”œâ”€â”€ models/             # æ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ algorithms/         # ç®—æ³•å®ç°
â”‚   â””â”€â”€ utils/              # å·¥å…·å‡½æ•°
â”œâ”€â”€ services/               # ä¸šåŠ¡æœåŠ¡å±‚
â”‚   â”œâ”€â”€ question_generator/ # é¢˜ç›®ç”ŸæˆæœåŠ¡
â”‚   â”œâ”€â”€ tutoring_system/    # æ™ºèƒ½åŠ©æ•™æœåŠ¡
â”‚   â””â”€â”€ analytics/          # åˆ†ææœåŠ¡
â”œâ”€â”€ infrastructure/         # åŸºç¡€è®¾æ–½å±‚
â”‚   â”œâ”€â”€ monitoring/         # ç›‘æ§ç³»ç»Ÿ
â”‚   â”œâ”€â”€ deployment/         # éƒ¨ç½²è„šæœ¬
â”‚   â””â”€â”€ security/           # å®‰å…¨ç»„ä»¶
â””â”€â”€ tests/                  # æµ‹è¯•ä»£ç 
    â”œâ”€â”€ unit/              # å•å…ƒæµ‹è¯•
    â”œâ”€â”€ integration/       # é›†æˆæµ‹è¯•
    â””â”€â”€ performance/       # æ€§èƒ½æµ‹è¯•
```

### APIè®¾è®¡è§„èŒƒ
```python
# æ ‡å‡†åŒ–çš„AIæœåŠ¡APIè®¾è®¡
from pydantic import BaseModel, Field
from typing import Optional, List

class GenerateQuestionRequest(BaseModel):
    """é¢˜ç›®ç”Ÿæˆè¯·æ±‚"""
    concept: str = Field(..., description="çŸ¥è¯†ç‚¹æ¦‚å¿µ")
    difficulty: float = Field(..., ge=0.0, le=1.0, description="éš¾åº¦ç³»æ•°")
    question_type: str = Field(..., description="é¢˜ç›®ç±»å‹")
    student_profile: Optional[dict] = Field(None, description="å­¦ç”Ÿç”»åƒ")

    class Config:
        schema_extra = {
            "example": {
                "concept": "äºŒæ¬¡å‡½æ•°",
                "difficulty": 0.6,
                "question_type": "é€‰æ‹©é¢˜",
                "student_profile": {
                    "grade": 8,
                    "learning_style": "visual"
                }
            }
        }

class GenerateQuestionResponse(BaseModel):
    """é¢˜ç›®ç”Ÿæˆå“åº”"""
    question_id: str = Field(..., description="é¢˜ç›®å”¯ä¸€æ ‡è¯†")
    content: str = Field(..., description="é¢˜ç›®å†…å®¹")
    options: Optional[List[str]] = Field(None, description="é€‰æ‹©é¢˜é€‰é¡¹")
    answer: str = Field(..., description="æ­£ç¡®ç­”æ¡ˆ")
    explanation: str = Field(..., description="è¯¦ç»†è§£æ")
    difficulty: float = Field(..., description="å®é™…éš¾åº¦")
    quality_score: float = Field(..., description="å†…å®¹è´¨é‡è¯„åˆ†")
    generation_time: float = Field(..., description="ç”Ÿæˆè€—æ—¶(ç§’)")

    class Config:
        schema_extra = {
            "example": {
                "question_id": "q_20241217_001",
                "content": "å·²çŸ¥äºŒæ¬¡å‡½æ•°f(x) = xÂ² - 4x + 3ï¼Œæ±‚å…¶é¡¶ç‚¹åæ ‡ã€‚",
                "answer": "(2, -1)",
                "explanation": "é€šè¿‡é…æ–¹æ³•æˆ–é¡¶ç‚¹å…¬å¼å¯æ±‚å¾—...",
                "difficulty": 0.58,
                "quality_score": 0.92,
                "generation_time": 1.8
            }
        }
```

*è´£ä»»ç»´æŠ¤äººï¼š[å¾…æŒ‡å®š] | å·¥ç¨‹åŒ–è¯„ä¼°ï¼šæ¯æœˆä¸€æ¬¡*